The code will run on GPU.
torch.Size([16, 18, 64, 64]) torch.Size([16])
Training of temporal stream net is starting and will be carried out on: cuda:0
Epoch of temporal stream: 0; Loss train: 2.266	 test: 2.229	 Accuracy train: 12.4%	 test: 23.3%
Epoch of temporal stream: 1; Loss train: 2.181	 test: 2.140	 Accuracy train: 22.2%	 test: 26.7%
Epoch of temporal stream: 2; Loss train: 2.101	 test: 2.077	 Accuracy train: 24.4%	 test: 25.0%
Epoch of temporal stream: 3; Loss train: 1.980	 test: 2.014	 Accuracy train: 33.8%	 test: 30.0%
Epoch of temporal stream: 4; Loss train: 1.900	 test: 1.977	 Accuracy train: 34.8%	 test: 33.3%
Epoch of temporal stream: 5; Loss train: 1.800	 test: 1.885	 Accuracy train: 42.6%	 test: 37.5%
Epoch of temporal stream: 6; Loss train: 1.699	 test: 1.873	 Accuracy train: 46.2%	 test: 39.2%
Epoch of temporal stream: 7; Loss train: 1.655	 test: 1.769	 Accuracy train: 47.4%	 test: 40.8%
Epoch of temporal stream: 8; Loss train: 1.512	 test: 1.743	 Accuracy train: 52.4%	 test: 42.5%
Epoch of temporal stream: 9; Loss train: 1.394	 test: 1.594	 Accuracy train: 53.8%	 test: 50.0%
Epoch of temporal stream: 10; Loss train: 1.349	 test: 1.542	 Accuracy train: 55.0%	 test: 50.0%
Epoch of temporal stream: 11; Loss train: 1.224	 test: 1.555	 Accuracy train: 59.8%	 test: 45.8%
Epoch of temporal stream: 12; Loss train: 1.153	 test: 1.536	 Accuracy train: 64.2%	 test: 47.5%
Epoch of temporal stream: 13; Loss train: 1.098	 test: 1.484	 Accuracy train: 65.6%	 test: 53.3%
Epoch of temporal stream: 14; Loss train: 1.032	 test: 1.405	 Accuracy train: 65.2%	 test: 53.3%
Epoch of temporal stream: 15; Loss train: 1.006	 test: 1.377	 Accuracy train: 66.2%	 test: 53.3%
Epoch of temporal stream: 16; Loss train: 0.889	 test: 1.558	 Accuracy train: 72.4%	 test: 55.8%
Epoch of temporal stream: 17; Loss train: 0.841	 test: 1.409	 Accuracy train: 73.2%	 test: 54.2%
Epoch of temporal stream: 18; Loss train: 0.832	 test: 1.443	 Accuracy train: 74.6%	 test: 51.7%
Epoch of temporal stream: 19; Loss train: 0.780	 test: 1.514	 Accuracy train: 76.8%	 test: 50.8%
Epoch of temporal stream: 20; Loss train: 0.719	 test: 1.423	 Accuracy train: 78.8%	 test: 53.3%
Epoch of temporal stream: 21; Loss train: 0.675	 test: 1.472	 Accuracy train: 78.2%	 test: 54.2%
Epoch of temporal stream: 22; Loss train: 0.609	 test: 1.535	 Accuracy train: 82.0%	 test: 53.3%
Epoch of temporal stream: 23; Loss train: 0.609	 test: 1.535	 Accuracy train: 82.4%	 test: 50.8%
Epoch of temporal stream: 24; Loss train: 0.561	 test: 1.507	 Accuracy train: 83.6%	 test: 55.8%
Epoch of temporal stream: 25; Loss train: 0.523	 test: 1.559	 Accuracy train: 84.6%	 test: 51.7%
Epoch of temporal stream: 26; Loss train: 0.524	 test: 1.469	 Accuracy train: 84.4%	 test: 55.8%
Epoch of temporal stream: 27; Loss train: 0.484	 test: 1.511	 Accuracy train: 86.6%	 test: 56.7%
Epoch of temporal stream: 28; Loss train: 0.435	 test: 1.626	 Accuracy train: 89.0%	 test: 55.8%
Epoch of temporal stream: 29; Loss train: 0.444	 test: 1.560	 Accuracy train: 88.2%	 test: 54.2%
Code finished!

------------------------------------------------------------
Sender: LSF System <lsfadmin@hpc.dtu.dk>
Subject: Job 26457866: <DualStreamTemporalNet> in cluster <dcc> Done

Job <DualStreamTemporalNet> was submitted from host <n-62-11-12> by user <s253818> in cluster <dcc> at Sun Oct 12 13:59:14 2025
Job was executed on host(s) <4*n-62-18-13>, in queue <c02516>, as user <s253818> in cluster <dcc> at Sun Oct 12 13:59:14 2025
</zhome/f2/a/224066> was used as the home directory.
</zhome/f2/a/224066/Project2/DualStream> was used as the working directory.
Started at Sun Oct 12 13:59:14 2025
Terminated at Sun Oct 12 14:01:47 2025
Results reported at Sun Oct 12 14:01:47 2025

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
#!/bin/sh
### ------------- specify queue name ----------------
#BSUB -q c02516
### ------------- specify gpu request----------------
#BSUB -gpu "num=1:mode=exclusive_process"
### ------------- specify job name ----------------
#BSUB -J DualStreamTemporalNet
### ------------- specify number of cores ----------------
#BSUB -n 4
#BSUB -R "span[hosts=1]"
### ------------- specify CPU memory requirements ----------------
#BSUB -R "rusage[mem=20GB]"
### ------------- specify wall-clock time (max allowed is 12:00)---------------- #BSUB -W 12:00
#BSUB -o OUTPUT_FILE%J.out
#BSUB -e OUTPUT_FILE%J.err
source /zhome/f2/a/224066/IDLCV/bin/activate
python /zhome/f2/a/224066/Project2/DualStream/DualStreamTemporalNet.py

------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   140.19 sec.
    Max Memory :                                 882 MB
    Average Memory :                             661.75 MB
    Total Requested Memory :                     81920.00 MB
    Delta Memory :                               81038.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                8
    Run time :                                   265 sec.
    Turnaround time :                            153 sec.

The output (if any) is above this job summary.



PS:

Read file <OUTPUT_FILE26457866.err> for stderr output of this job.

